{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import pickle\n",
        "import time\n",
        "import tarfile\n",
        "import datetime\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow import concat, repeat\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from sklearn.utils import shuffle\n",
        "from skimage.transform import resize\n",
        "import nltk.translate.bleu_score as bleu\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.backend import expand_dims \n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from tensorflow.keras.layers import TimeDistributed, concatenate, Concatenate, Input, Softmax, RNN, Dense, Embedding, LSTM, Layer, Dropout, GRU\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.applications.densenet import preprocess_input\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "6fQqwNnxpT8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "HfoTgGM9pXzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/mimic_cxr/train.findings.tok\", \"r\") as file:\n",
        "    sentences = file.readlines()\n",
        "sentences = [sentence.strip() for sentence in sentences]\n",
        "train_text_df = pd.DataFrame(sentences, columns=['findings'])\n",
        "train_text_df.shape"
      ],
      "metadata": {
        "id": "9Cxccm7PpaOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/mimic_cxr/train.impression.tok\", \"r\") as file:\n",
        "    sentences = file.readlines()\n",
        "sentences = [sentence.strip() for sentence in sentences]\n",
        "train_text_summary_output_df = pd.DataFrame(sentences, columns=['impressions'])\n",
        "train_text_summary_output_df.shape"
      ],
      "metadata": {
        "id": "jLeSNaPjpb5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Image embeddings were already available as a step in third approach, so using the results directly here.\n",
        "image_embeddings_train_npz = np.load('/content/drive/My Drive/mimic_cxr/chexpert_embeddings_train_final.npz')\n",
        "image_embeddings_train_np = image_embeddings_train_npz['a']\n",
        "image_embeddings_train_np.shape"
      ],
      "metadata": {
        "id": "p4M2vFMIpeVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.concat([train_text_df, train_text_summary_output_df, pd.Series(list(image_embeddings_train_np), name='image_features')], axis=1)\n",
        "train_df['dec_ip'] = '<start>' + ' ' + train_df['impressions'].astype(str)\n",
        "train_df['dec_op'] = train_df['impressions'].astype(str) + ' ' +'<end>'\n",
        "train_df['impressions'] = '<start> ' + train_df['impressions'] + ' <end>'\n",
        "train_df.shape"
      ],
      "metadata": {
        "id": "N2EjwXLBpgkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "OeZDQqsrpiJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_image_features = image_embeddings_train_np.copy()\n",
        "train_image_features = np.vstack(train_image_features).astype(np.float)"
      ],
      "metadata": {
        "id": "AhZBlf_jcpEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbAMwHZYeqfI"
      },
      "outputs": [],
      "source": [
        "train_ff = train_df[10000:50000]\n",
        "validation_ff = train_df[:10000]\n",
        "train_image_features_ff = train_image_features[10000:50000]\n",
        "validation_image_features_ff = train_image_features[:10000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWuF9K8XTXSd"
      },
      "outputs": [],
      "source": [
        "token = Tokenizer( filters='!\"#$%&()*+,-/:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "token.fit_on_texts(train_ff['findings'])\n",
        "\n",
        "token.word_index['<pad>'] = 0\n",
        "token.index_word[0] = '<pad>'\n",
        "all_words_len = len(token.word_index) + 1\n",
        "\n",
        "train_decoder_input = token.texts_to_sequences(train_ff.dec_ip)\n",
        "train_decoder_output = token.texts_to_sequences(train_ff.dec_op)\n",
        "val_decoder_input = token.texts_to_sequences(validation_ff.dec_ip)\n",
        "val_decoder_output = token.texts_to_sequences(validation_ff.dec_op)\n",
        "\n",
        "max_len = 150\n",
        "decoder_input = pad_sequences(train_decoder_input, maxlen=max_len, padding='post')\n",
        "decoder_output =  pad_sequences(train_decoder_output, maxlen=max_len, padding='post') \n",
        "val_decoder_input = pad_sequences(val_decoder_input, maxlen=max_len, padding='post') \n",
        "val_decoder_output = pad_sequences(val_decoder_output, maxlen=max_len, padding='post')\n",
        "\n",
        "word_index = {}\n",
        "index_word = {}\n",
        "for key, value in (token.word_index).items(): \n",
        "    word_index[key] = value\n",
        "    index_word[value] = key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snayM6JMTl2X"
      },
      "outputs": [],
      "source": [
        "batch_size     = 100\n",
        "buffer_len    = 500\n",
        "\n",
        "train_final_dataset = tf.data.Dataset.from_tensor_slices(((train_image_features_ff, decoder_input), decoder_output))\n",
        "train_final_dataset = train_final_dataset.shuffle(buffer_len).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "validation_final_dataset = tf.data.Dataset.from_tensor_slices(((validation_image_features_ff,val_decoder_input),val_decoder_output))\n",
        "validation_final_dataset = validation_final_dataset.shuffle(buffer_len).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80z3fyssTtvv"
      },
      "outputs": [],
      "source": [
        "class CustomEncoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self,lstm_units):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.lstm_units = lstm_units\n",
        "        self.dense      = Dense(self.lstm_units, kernel_initializer=\"glorot_uniform\", name = 'encoder_dense_layer')\n",
        "        \n",
        "    def initialize_states(self, batch_size):\n",
        "      \n",
        "        self.batch_size  = batch_size\n",
        "        self.in_state       = tf.zeros((self.batch_size, self.lstm_units))\n",
        "      \n",
        "        return self.in_state\n",
        "    \n",
        "    def call(self, inp):\n",
        "      \n",
        "        enc_op = self.dense(inp)\n",
        "      \n",
        "        return enc_op  \n",
        "\n",
        "\n",
        "class CustomAttentionLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self,attn_units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn_units = attn_units  \n",
        "\n",
        "        self.dense_1    =  tf.keras.layers.Dense(self.attn_units, kernel_initializer=\"glorot_uniform\", name='Concat_dense_1')\n",
        "        self.dense_2    =  tf.keras.layers.Dense(self.attn_units, kernel_initializer=\"glorot_uniform\", name='Concat_dense_2')\n",
        "        self.final_dense_layer=  tf.keras.layers.Dense(1, kernel_initializer=\"glorot_uniform\", name = 'final_dense_layer_layer')\n",
        "  \n",
        "    def call(self,x):\n",
        "    \n",
        "        self.dec_hidden_state, self.enc_op = x\n",
        "        self.dec_hidden_state = tf.expand_dims(self.dec_hidden_state,axis = 1)\n",
        "    \n",
        "        score = self.final_dense_layer(tf.nn.tanh(self.dense_1(self.dec_hidden_state) + self.dense_2(self.enc_op)))\n",
        "    \n",
        "        attn_wghts    = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attn_wghts * self.enc_op\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)   \n",
        "    \n",
        "        return context_vector, attn_wghts\n",
        "\n",
        "\n",
        "class CustomSingleStepDecoder(tf.keras.Model):\n",
        "    def __init__(self, all_words_len, embedding_dim, lstm_units, attn_units):\n",
        "        super().__init__()\n",
        "      \n",
        "        self.lstm_units     = lstm_units\n",
        "        self.all_words_len     = all_words_len\n",
        "        self.embedding_dim  = embedding_dim\n",
        "        self.attn_units= attn_units\n",
        "      \n",
        "        self.dense       = Dense(self.all_words_len, kernel_initializer=\"glorot_uniform\", name ='onestep_dense')\n",
        "        self.attention   = CustomAttentionLayer( self.attn_units)\n",
        "        self.decoder_emb = Embedding(self.all_words_len, self.embedding_dim, trainable = True , name = 'Decoder_embedding')           \n",
        "        self.decoder_gru = GRU(self.lstm_units, return_state=True, return_sequences=True, name=\"Decoder_LSTM\") \n",
        "      \n",
        "        self.dropout_layer_1 = Dropout(0.3, name = 'dropout_layer_1')\n",
        "        self.dropout_layer_2 = Dropout(0.3, name = 'dropout_layer_2')\n",
        "        self.dropout_layer_3 = Dropout(0.3, name = 'dropout_layer_3')\n",
        "  \n",
        "    @tf.function\n",
        "    def call(self,x,training=None):\n",
        "    \n",
        "        self.dec_ip, self.enc_op, self.state_h = x\n",
        "\n",
        "        embd_layer_op = self.decoder_emb(self.dec_ip)\n",
        "        embd_layer_op = self.dropout_layer_1(embd_layer_op)\n",
        "    \n",
        "        y = [self.state_h, self.enc_op]\n",
        "        context_vector, attn_wghts = self.attention(y)\n",
        "\n",
        "        final_decoder_input = tf.concat([tf.expand_dims(context_vector, 1),embd_layer_op], -1)\n",
        "        final_decoder_input = self.dropout_layer_2(final_decoder_input)\n",
        "\n",
        "        gru_layer_output, hidden_state = self.decoder_gru(final_decoder_input, initial_state=self.state_h)\n",
        "    \n",
        "        gru_layer_output = tf.reshape(gru_layer_output, (-1, gru_layer_output.shape[2]))\n",
        "        gru_layer_output = self.dropout_layer_3(gru_layer_output)\n",
        "\n",
        "        output = self.dense(gru_layer_output)\n",
        "\n",
        "        return output,hidden_state,attn_wghts,context_vector\n",
        "\n",
        "\n",
        "class CustomDecoder(tf.keras.Model):\n",
        "    def __init__(self, all_words_len, embedding_dim, lstm_units, attn_units):\n",
        "        super().__init__()\n",
        "\n",
        "        self.lstm_units     = lstm_units\n",
        "        self.all_words_len     = all_words_len\n",
        "        self.embedding_dim  = embedding_dim\n",
        "        self.attn_units= attn_units\n",
        "      \n",
        "        self.onestepdecoder = CustomSingleStepDecoder(self.all_words_len, self.embedding_dim, self.lstm_units, self.attn_units)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, x,training=None):\n",
        "        \n",
        "        self.dec_ip, self.enc_op, self.dec_hidden_state = x\n",
        "        model_outputs = tf.TensorArray(tf.float32,size = self.dec_ip.shape[1], name = 'output_arrays' )\n",
        "        \n",
        "        for t in tf.range(self.dec_ip.shape[1]):\n",
        "          \n",
        "            y = [self.dec_ip[:,t:t+1],self.enc_op, self.dec_hidden_state]\n",
        "            output,hidden_state,attn_wghts,context_vector = self.onestepdecoder(y)\n",
        "          \n",
        "            self.dec_hidden_state = hidden_state\n",
        "            model_outputs = model_outputs.write(t,output)\n",
        "        \n",
        "        model_outputs = tf.transpose(model_outputs.stack(),[1,0,2])\n",
        "        \n",
        "        return model_outputs\n",
        "\n",
        "\n",
        "class CustomEncoderDecoder(tf.keras.Model):\n",
        "    def __init__(self, all_words_len, embedding_dim, lstm_units, attn_units, batch_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.all_words_len     = all_words_len\n",
        "        self.batch_size     = batch_size\n",
        "        self.lstm_units     = lstm_units\n",
        "        self.embedding_dim  = embedding_dim\n",
        "        self.attn_units= attn_units\n",
        "        \n",
        "        self.encoder = CustomEncoder(self.lstm_units)\n",
        "        self.decoder = CustomDecoder(all_words_len, embedding_dim, lstm_units, attn_units)\n",
        "        self.dense   = Dense(self.all_words_len, kernel_initializer=\"glorot_uniform\", name = 'enc_dec_dense')\n",
        "\n",
        "  \n",
        "    def call(self,data):\n",
        "    \n",
        "        self.inputs, self.outputs = data[0], data[1]\n",
        "\n",
        "        self.enc_hidden_layer = self.encoder.initialize_states(self.batch_size)\n",
        "        self.enc_op = self.encoder(self.inputs)\n",
        "    \n",
        "        x = [self.outputs,self.enc_op,self.enc_hidden_layer]\n",
        "        output = self.decoder(x)\n",
        "    \n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkgHZ87PURos"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "checkpoint_path = \"./training_2/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "   checkpoint_path, verbose=1, save_weights_only=True,\n",
        "   # Save weights, every epoch.\n",
        "   save_freq='epoch')"
      ],
      "metadata": {
        "id": "z07NREMBnLnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJdk-G6MU8-g"
      },
      "outputs": [],
      "source": [
        "lstm_units     = 256\n",
        "embedding_dim  = 300\n",
        "attn_units= 64\n",
        "tf.keras.backend.clear_session()\n",
        "Attention_model = CustomEncoderDecoder(all_words_len,embedding_dim,lstm_units,attn_units,batch_size)\n",
        "Attention_model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=loss_function)\n",
        "Attention_model.fit(train_final_dataset, validation_data=validation_final_dataset, epochs=1, callbacks = [cp_callback], shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(Attention_model, open('/content/drive/My Drive/cv_model.pkl','wb'))"
      ],
      "metadata": {
        "id": "UfIfw-iBO1L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "id": "UxABljtD1KzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjG0MAiXjpPj"
      },
      "outputs": [],
      "source": [
        "def measure_performance(img_data, model):\n",
        "    img_features = img_data[2].reshape((1,1024))\n",
        "    result = ''\n",
        "    init_state  = model.layers[0].initialize_states(1)\n",
        "    text_seq      = [['<start>', init_state, 0]]\n",
        "    encoder_output       = model.layers[0](img_features)\n",
        "\n",
        "    decoder_hidden_state = init_state\n",
        "\n",
        "    max_seq_len = 75\n",
        "    top_k_words_count = 3\n",
        "    final_seq = []\n",
        "\n",
        "    for i in range(max_seq_len):\n",
        "        new_seq = []\n",
        "        prob_list = []\n",
        "        \n",
        "        for seq,state,score in text_seq:\n",
        "\n",
        "            cur_vec = np.reshape(word_index[seq.split(\" \")[-1]],(1,1))\n",
        "            decoder_hidden_state = state\n",
        "            x = [cur_vec, encoder_output, decoder_hidden_state]\n",
        "            output,hidden_state,attn_wghts,context_vector = model.get_layer('decoder_1').onestepdecoder(x)\n",
        "            output = tf.nn.softmax(output)\n",
        "            top_words = np.argsort(output).flatten()[-top_k_words_count:]\n",
        "            for index in top_words:\n",
        "         \n",
        "                predicted = [seq + ' '+ index_word[index], hidden_state, score-np.log(np.array(output).flatten()[index])]\n",
        "                prob_list.append(predicted)\n",
        "\n",
        "        text_seq = sorted(prob_list, key = lambda l: l[2])[:top_k_words_count]\n",
        "\n",
        "        count = 0\n",
        "        for seq,state,score in text_seq:\n",
        "            if seq.split(\" \")[-1] == '<end>':\n",
        "                score = score/len(seq)\n",
        "                final_seq.append([seq,state,score])\n",
        "                count+=1\n",
        "            else:\n",
        "                new_seq.append([seq,state,score])\n",
        "        \n",
        "        text_seq = new_seq\n",
        "        top_k_words_count= top_k_words_count - count\n",
        "        if not text_seq:\n",
        "            break        \n",
        "        else:\n",
        "            continue\n",
        "    if len(final_seq) >0:\n",
        "          final_seq = sorted(final_seq, reverse=True, key = lambda l: l[2])\n",
        "          text_seq = final_seq[-1]\n",
        "          result = text_seq[0][8:]\n",
        "    else:\n",
        "          result = new_seq[-1][0]\n",
        "    print(\"Predicted text:\",result)\n",
        "    print('BLEU Score:',sentence_bleu(img_data[1], result))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/My Drive/cv_model.pkl', 'rb') as f:\n",
        "    att_model = pickle.load(f)"
      ],
      "metadata": {
        "id": "3VmOzvu4OOzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF-QiVBSXzX9",
        "outputId": "58117fee-ced0-472d-ef58-18f57ff51f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>>>>>>>>img_data ['<start> Frontal and lateral views of the chest demonstrate normal cardiomediastinal silhouette. The lungs are clear. There is no pneumothorax, vascular congestion, or pleural effusion. Several cholecystectomy clips are seen in the gallbladder fossa. <end>'\n",
            " 'No evidence of pneumonia.'\n",
            " array([0.002626  , 0.0218488 , 0.08873988, ..., 0.00113838, 0.01137492,\n",
            "        0.16669281])\n",
            " '<start> Frontal and lateral views of the chest demonstrate normal cardiomediastinal silhouette. The lungs are clear. There is no pneumothorax, vascular congestion, or pleural effusion. Several cholecystectomy clips are seen in the gallbladder fossa.'\n",
            " 'Frontal and lateral views of the chest demonstrate normal cardiomediastinal silhouette. The lungs are clear. There is no pneumothorax, vascular congestion, or pleural effusion. Several cholecystectomy clips are seen in the gallbladder fossa. <end>']\n",
            ">>>>>>>>>>>>>>>>>>1\n",
            ">>>>>>>>>>>>>>>>>>2\n",
            ">>>>>>>>>>>>>>>>>>3\n",
            "Predicted Report : pa and lateral views of the chest were obtained. the lungs are clear. there is no focal consolidation pleural effusion or pneumothorax. the heart is normal in size. the mediastinal and hilar contours are unchanged. the lungs are clear. there is no focal consolidation pleural effusion or pneumothorax. <end>\n",
            "BLEU Score :- 9.732148607018152e-232 \n",
            "\n",
            "CPU times: user 925 ms, sys: 19.2 ms, total: 944 ms\n",
            "Wall time: 2.06 s\n"
          ]
        }
      ],
      "source": [
        "measure_performance(train_df.values[10001], att_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}